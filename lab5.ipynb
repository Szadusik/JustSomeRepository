{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GjLwr7LHju9z"
   },
   "source": [
    "# Multinomial logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0Y7HX_yju91"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mkl\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "np.random.seed(1234)\n",
    "mkl.set_num_threads(4)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usefull imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    '''\n",
    "    Convert label indices into one-hot vectors\n",
    "    \n",
    "    Args:\n",
    "        labels: n-element array with label indices.\n",
    "    \n",
    "    Returns:\n",
    "        n times k matrix where each row is a one-hot encoding\n",
    "        of a class label. k - number of classes.\n",
    "    '''\n",
    "    one_hot = np.zeros(shape = (labels.shape[0], np.max(labels) + 1))\n",
    "    one_hot[np.arange(labels.shape[0]), labels] = 1\n",
    "    \n",
    "    return one_hot.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_params(ax, W):\n",
    "    '''\n",
    "    Draw parameters of a multinomial logistic regression in a tiles-like plot.\n",
    "    \n",
    "    Args:\n",
    "        ax:    Axis for plotting.\n",
    "        W:     Parameters of a multinomial logistic regression model.\n",
    "               Shape (d+1) times k, where k is the number of classes and\n",
    "               d is the number of explanatory variables.\n",
    "    '''\n",
    "    F = np.reshape(W[:-1, :].T, newshape=(2, -1, 28, 28))\n",
    "    tiles(ax, F)\n",
    "\n",
    "\n",
    "def tiles(ax, M):\n",
    "    '''\n",
    "    Draw volume M in a tiles-like plot.\n",
    "    \n",
    "    Args:\n",
    "        ax:    Axis for plotting.\n",
    "        M:     Volume to plot. Shape: r times c times h times w, where\n",
    "               r is the number of rows in the output plot,\n",
    "               c is the number of columns in the output plot,\n",
    "               h is the height of a single tile,\n",
    "               w is the width of a single tile.\n",
    "    '''\n",
    "    rows_count = M.shape[0]\n",
    "    cols_count = M.shape[1]\n",
    "    tile_height = M.shape[2]\n",
    "    tile_width = M.shape[3]\n",
    "    \n",
    "    space_between_tiles = 2\n",
    "    img_matrix = np.empty(shape=(rows_count * (tile_height + space_between_tiles) - space_between_tiles,  \n",
    "                                 cols_count * (tile_width + space_between_tiles) - space_between_tiles))\n",
    "    img_matrix.fill(np.nan)\n",
    "\n",
    "    for r in range(rows_count):\n",
    "        for c in range(cols_count):\n",
    "            x_0 = r * (tile_height + space_between_tiles)\n",
    "            y_0 = c * (tile_width + space_between_tiles)\n",
    "            ex_min = np.min(M[r, c])\n",
    "            ex_max = np.max(M[r, c])\n",
    "            img_matrix[x_0:x_0 + tile_height, y_0:y_0 + tile_width] = (M[r, c] - ex_min) / (ex_max - ex_min)\n",
    "    \n",
    "    ax.matshow(img_matrix, cmap='gray', interpolation='none')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset\n",
    "\n",
    "In this lab we will use [MNIST handwritten digits dataset](http://yann.lecun.com/exdb/mnist/). Lets import and prepare this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Compressed file ended before the end-of-stream marker was reached",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2b52cbc7da9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdigits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\mnist\\__init__.py\u001b[0m in \u001b[0;36mtrain_images\u001b[1;34m()\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \"\"\"\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdownload_and_parse_mnist_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train-images-idx3-ubyte.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\mnist\\__init__.py\u001b[0m in \u001b[0;36mdownload_and_parse_mnist_file\u001b[1;34m(fname, target_dir, force)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mfopen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'.gz'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparse_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\mnist\\__init__.py\u001b[0m in \u001b[0;36mparse_idx\u001b[1;34m(fd)\u001b[0m\n\u001b[0;32m    109\u001b[0m                                     fd.read(4 * num_dimensions))\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyteswap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# looks like array.array reads data as little endian\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\gzip.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\gzip.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    496\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m                 raise EOFError(\"Compressed file ended before the \"\n\u001b[0m\u001b[0;32m    499\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mnist\n",
    "\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "digits = np.reshape(mnist.train_images()[:12*24], newshape=(12, 24, 28, 28))\n",
    "tiles(plt.gca(), digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reshape each $28 \\times 28$ pixel image into a $1 \\times 784$ vector and append a fixed $1$ at the end. We will also convert images from $255$ from 255255 gray levels to $\\langle 0, 1 \\rangle$ interval. Finally, we will pick a random subset of 20,000 examples for training. The test part of the MNIST dataset will be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Compressed file ended before the end-of-stream marker was reached",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e6445771872e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mDIGIT_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmnist_train_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mmnist_train_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\mnist\\__init__.py\u001b[0m in \u001b[0;36mtrain_images\u001b[1;34m()\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \"\"\"\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdownload_and_parse_mnist_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train-images-idx3-ubyte.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\mnist\\__init__.py\u001b[0m in \u001b[0;36mdownload_and_parse_mnist_file\u001b[1;34m(fname, target_dir, force)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mfopen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'.gz'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparse_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\mnist\\__init__.py\u001b[0m in \u001b[0;36mparse_idx\u001b[1;34m(fd)\u001b[0m\n\u001b[0;32m    109\u001b[0m                                     fd.read(4 * num_dimensions))\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyteswap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# looks like array.array reads data as little endian\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\gzip.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\gzip.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    496\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m                 raise EOFError(\"Compressed file ended before the \"\n\u001b[0m\u001b[0;32m    499\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
     ]
    }
   ],
   "source": [
    "##### Train set #####\n",
    "\n",
    "DATASET_SIZE = 20000 # 60000 for whole dataset\n",
    "DIGIT_SIZE = 28\n",
    "\n",
    "mnist_train_images = mnist.train_images().astype(np.float32) / 255.0\n",
    "mnist_train_labels = mnist.train_labels()\n",
    "\n",
    "order = np.random.permutation(len(mnist_train_images))\n",
    "mnist_train_images = mnist_train_images[order]\n",
    "mnist_train_labels = mnist_train_labels[order]\n",
    "\n",
    "mnist_train_images = np.reshape(mnist_train_images[:DATASET_SIZE],\n",
    "                                newshape=(DATASET_SIZE, DIGIT_SIZE*DIGIT_SIZE))\n",
    "\n",
    "ones = np.ones((mnist_train_images.shape[0], 1))\n",
    "mnist_train_images = np.concatenate((mnist_train_images, ones), axis=1)\n",
    "\n",
    "mnist_train_labels = mnist_train_labels[:DATASET_SIZE]\n",
    "mnist_train_labels = one_hot_encode(mnist_train_labels)\n",
    "\n",
    "##### Validation set #####\n",
    "\n",
    "mnist_val_images = mnist.test_images().astype(np.float32) / 255.0\n",
    "mnist_val_images = np.reshape(mnist_val_images, newshape=(-1, DIGIT_SIZE*DIGIT_SIZE))\n",
    "\n",
    "ones = np.ones((mnist_val_images.shape[0], 1))\n",
    "mnist_val_images = np.concatenate((mnist_val_images, ones), axis=1)\n",
    "\n",
    "mnist_val_labels = mnist.test_labels()\n",
    "mnist_val_labels = one_hot_encode(mnist_val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial logistic regression model\n",
    "\n",
    "Our goal is to fit a multinomial logistic regression model to the MNIST dataset. We start by implementing the link function in this model.\n",
    "\n",
    "### Softmax link function\n",
    "\n",
    "Implement `softmax` function which takes an $n \\times k$ matrix $\\mathbf{Z}$ with class logits and returns an $n \\times k$ matrix with categorical probability distributions for observations in $\\mathbf{Z}$. The dimensions are: $n$ - number of observations, $k$ - number of classes.\n",
    "\n",
    "---\n",
    "\n",
    "**Implementation note**. Imagine that $z_{ij} = 100$. Then in a typical floating-point precision we have:\n",
    "\n",
    "$$\\large\n",
    "p_{ij} = \\frac{\\mathrm{e}^{z_{ij}}}{\\sum_{l=1}^k \\mathrm{e}^{z_{il}}}\n",
    "       = \\frac{\\mathrm{e}^{z_{ij}}}{\\mathrm{e}^{z_{ij}} + \\sum_{\\substack{l=1 \\\\ l \\neq j}}^k \\mathrm{e}^{z_{il}}}\n",
    "       = \\frac{\\mathrm{e}^{100}}{\\mathrm{e}^{100} + \\sum_{\\substack{l=1 \\\\ l \\neq j}}^k \\mathrm{e}^{z_{il}}}\n",
    "       = \\frac{\\mathrm{inf}}{\\mathrm{inf}} = \\mathrm{nan}\n",
    "$$\n",
    "\n",
    "However, note that for every finite $u \\in \\mathbb{R}$ we have:\n",
    "\n",
    "$$\\large\n",
    "p_{ij} = \\frac{\\mathrm{e}^{z_{ij}}}{\\sum_{l=1}^k \\mathrm{e}^{z_{il}}}\n",
    "       = \\frac{\\mathrm{e}^{-u} \\mathrm{e}^{z_{ij}}}{\\mathrm{e}^{-u} \\sum_{l=1}^k \\mathrm{e}^{z_{il}}}\n",
    "       = \\frac{\\mathrm{e}^{z_{ij} - u}}{\\sum_{l=1}^k \\mathrm{e}^{z_{il} - u}}\n",
    "$$\n",
    "\n",
    "So to implement `softmax` in a numerically stable manner, we can simply shift the logits (independently for each observation) so that: $\\mathop{\\mathrm{max}}_{l = 1,\\ldots, k} z_{il} = 0$. That is, we set:\n",
    "\n",
    "$$\\large\n",
    "z_{ij} \\leftarrow z_{ij} - \\mathop{\\mathrm{max}}_{l = 1,\\ldots, k} z_{il}\n",
    "$$\n",
    "\n",
    "This basically turns an overflow issue into an underflow that we can disregard. Use this trick when implementing `softmax` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    #raise Exception('Implement softmax function')\n",
    "    Z -= np.amax(Z, axis=1).reshape(-1, 1)\n",
    "    return np.exp(Z) / np.exp(Z).sum(axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "\n",
    "Next, we need to implement a cost function for our model and its gradient w.r.t the model parameters. Note that the cross-entropy cost increases proportionally to the number of input observations $n$. This is undesirable from an optimization point of view: the learning rate in gradient descent needs to be adjusted to the number of training observations. To avoid that issue we will calculate an <u>average</u> cross-entropy cost per input observation. That is, we will divide the cross-entropy cost (and therefore also its gradient) by $n$.\n",
    "\n",
    "---\n",
    "\n",
    "Implement `xentropy` function which takes as an input:\n",
    "- An $n \\times k$ matrix $\\mathbf{S}$ with categorical probability distributions for $n$ input observations.\n",
    "- An $n \\times k$ matrix $\\mathbf{T}$ with one-hot encoded class labels for $n$ input observations.\n",
    "\n",
    "and returns an average (per input observation) cross-entropy between $\\mathbf{T}$ and $\\mathbf{S}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xentropy(S, T):\n",
    "    #raise Exception('Implement xentropy function')\n",
    "    return -np.sum(T * np.log(S)) / S.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement `grad_xentropy` function which takes as an input:\n",
    "- An $n \\times (d+1)$ matrix $\\mathbf{X}$ with explanatory variables for $n$ input observations.\n",
    "- An $n \\times k$ matrix $\\mathbf{S}$ with categorical probability distributions for observations in $\\mathbf{X}$.\n",
    "- An $n \\times k$ matrix $\\mathbf{T}$ with one-hot encoded class labels for observations in $\\mathbf{X}$.\n",
    "\n",
    "and returns a gradient of the average (per input observation) cross-entropy between $\\mathbf{T}$ and $\\mathbf{S}$. We assume a standard multinomial logistic regression parametrization:\n",
    "\n",
    "\\begin{align} \\large\n",
    "\\mathbf{S}_{ij} & = \\frac{\\mathrm{e}^{z_{ij}}}{\\sum_{l=1}^k \\mathrm{e}^{z_{il}}}, \\\\[1em]\n",
    "\\left[z_{ij}\\right]_{n \\times k} & = \\mathbf{Z} = \\mathbf{XW},\n",
    "\\end{align}\n",
    "\n",
    "and return the gradient w.r.t the model parameters: $\\mathbf{W}_{\\left(d+1\\right) \\times k}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_xentropy(X, S, T):\n",
    "    #raise Exception('Implement grad_xentropy function')\n",
    "    return X.T @ (S - T) / S.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent training\n",
    "\n",
    "We are now ready to implement a maximum likelihood estimation for multinomial logistic regression model. We begin with few utility functions.\n",
    "\n",
    "Implement `classify` function which takes as an input\n",
    "- An $(d+1) \\times k$ matrix $\\mathbf{W}$ with parameters of a multinomial logistic regression model.\n",
    "- An $n \\times (d+1)$ matrix $\\mathbf{X}$ with explanatory variables for $n$ input observations.\n",
    "\n",
    "and returns an $n \\times k$ NumPy array with predicted class labels in one-hot encoding. We assume that the class predicted for a given observation is the one with the largest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(W, X):\n",
    "    Z = X @ W\n",
    "    S = softmax(Z)\n",
    "    res = S == np.max(S, axis=1, keepdims=True)\n",
    "    return res * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(P, T):\n",
    "    '''\n",
    "    Calculate classification accuracy.\n",
    "    \n",
    "    Args:\n",
    "        P: predicted labels in one-hot encoding,\n",
    "           shape n times k.\n",
    "        T: true labels in one-hot encoding,\n",
    "           shape n times k.           \n",
    "    \n",
    "    Returns:\n",
    "        Percentage of correctly predicted labels.\n",
    "    '''\n",
    "    accuracy = np.sum(P * T) / P.shape[0]\n",
    "    return 100.0 * accuracy\n",
    "\n",
    "\n",
    "def print_log(step, cost, train_acc, val_acc):\n",
    "    '''\n",
    "    A utility function used to display the progress of gd_fit.\n",
    "    '''\n",
    "    log = 'Step {:3d}\\tcost value: {:5.2f},\\ttrain accuracy: {:5.2f},\\t' \\\n",
    "          'validation accuracy: {:5.2f}'\n",
    "    log = log.format(step, cost.item(), train_acc.item(), val_acc.item())\n",
    "    \n",
    "    print(log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will minimize the cost function with gradient descent. Complete the implementation of `gd_fit` function following comments in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd_fit(W0, X, T, X_val, T_val, lr=1.0, steps=100, log_every=5):\n",
    "    '''\n",
    "    Fit multinomial logistic regression model with gradient descent.\n",
    "    \n",
    "    Args:\n",
    "        W0:        An array with initial parameter values, shape (d+1) times k.\n",
    "        X:         An array with explanatory variables for input (train) observations,\n",
    "                   shape n times (d+1).\n",
    "        T:         An array with one-hot encoded class labels for input (train) observations, \n",
    "                   shape n times k.\n",
    "        X_val:     An array with explanatory variables for validation observations,\n",
    "                   shape m times (d+1).\n",
    "        T_val:     An array with one-hot encoded class labels for validation observations, \n",
    "                   shape m times k.\n",
    "        lr:        Learning rate.\n",
    "        steps:     Number of gradient descent steps to perform.\n",
    "        log_every: Number of steps between progress logs.\n",
    "    \n",
    "    Returns:\n",
    "        An (d+1) times k NumPy array with fitted parameters.\n",
    "    '''\n",
    "    n = X.shape[0]\n",
    "    W = np.copy(W0)\n",
    "    \n",
    "    for step in range(steps):\n",
    "        # Assuming that current model parameters are in `W`, calculate the value of\n",
    "        # the cost function and store it in `cost_val` variable.\n",
    "        \n",
    "        #raise Exception('Complete implementation of gd_fit funcion')\n",
    "        Z = X @ W\n",
    "        S = softmax(Z)\n",
    "        cost_val = xentropy(S, T)\n",
    "        \n",
    "        # Next, calculate the gradient of the cost function w.r.t the parameters\n",
    "        # in `W`. Use this gradient matrix to update `W` (according to the gradient\n",
    "        # descent update rule).\n",
    "        \n",
    "        #raise Exception('Complete implementation of gd_fit funcion')\n",
    "        \n",
    "        grad_val = grad_xentropy(X, S, T)\n",
    "        W = W - lr * grad_val\n",
    "        \n",
    "        \n",
    "        P_train = classify(W, X)\n",
    "        train_acc = calc_acc(P_train, T)\n",
    "        \n",
    "        P_val = classify(W, X_val)\n",
    "        val_acc = calc_acc(P_val, T_val)\n",
    "        \n",
    "        if step == 0 or (step + 1) % log_every == 0:\n",
    "            print_log(step+1, cost_val, train_acc, val_acc)\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting multinomial logistic regression model to MNIST.\n",
    "\n",
    "Lets prepare and plot some initial parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 101,
       "width": 237
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "W0 = np.random.randn(DIGIT_SIZE*DIGIT_SIZE + 1, 10)\n",
    "\n",
    "fig = plt.figure(figsize=(4, 2))\n",
    "draw_params(plt.gca(), W0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fit multinomial logistic regression model to the MNIST dataset. Initially we do 200 gradient descent steps starting from `W0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist_train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-7a67c4ea3798>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m W = gd_fit(W0,\n\u001b[1;32m----> 2\u001b[1;33m            \u001b[0mmnist_train_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnist_train_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m            \u001b[0mmnist_val_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnist_val_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m            lr=3.0, steps=200, log_every=10)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist_train_images' is not defined"
     ]
    }
   ],
   "source": [
    "W = gd_fit(W0,\n",
    "           mnist_train_images, mnist_train_labels,\n",
    "           mnist_val_images, mnist_val_labels,\n",
    "           lr=3.0, steps=200, log_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we continue with additional 300 steps using a lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = gd_fit(W,\n",
    "           mnist_train_images, mnist_train_labels,\n",
    "           mnist_val_images, mnist_val_labels,\n",
    "           lr=0.3, steps=300, log_every=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the fitted parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 2))\n",
    "draw_params(plt.gca(), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting regularized multinomial logistic regression model to MNIST.\n",
    "\n",
    "Cross entropy cost function is convex but it is <u>not</u> strictly convex. We can turn it into a strictly convex cost function by adding a regularization term that penalizes magnitudes of model parameters:\n",
    "\n",
    "$$ \\large\n",
    "\\mathcal{L}_R\\left(\\mathbf{W}\\right) = \\mathcal{L}\\left(\\mathbf{W}\\right) +\n",
    "                                       \\frac{\\lambda}{2}\\sum_{i=1}^{d+1}\\sum_{j=1}^k w_{ij}^2,\n",
    "$$\n",
    "\n",
    "where $\\mathcal{L}\\left(\\mathbf{W}\\right)$ is the cross entropy cost.\n",
    "\n",
    "This is the same regularization that we used in ridge regression, and it can be derived as a MAP estimate in a Bayesian logistic regression model with Gaussian prior on model parameters (we do not need a conjugate prior to find the cost function for a MAP estimate). Let's implement this variant of the logistic regression model.\n",
    "\n",
    "Complete the implementation of `gd_fit_reg` function following comments in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd_fit_reg(W0, X, T, X_val, T_val, l2=0.005, lr=1.0, steps=100, log_every=5):\n",
    "    '''\n",
    "    Fit multinomial logistic regression model with gradient descent.\n",
    "    \n",
    "    Args:\n",
    "        W0:        An array with initial parameter values, shape (d+1) times k.\n",
    "        X:         An array with explanatory variables for input (train) observations,\n",
    "                   shape n times (d+1).\n",
    "        T:         An array with one-hot encoded class labels for input (train) observations, \n",
    "                   shape n times k.\n",
    "        X_val:     An array with explanatory variables for validation observations,\n",
    "                   shape m times (d+1).\n",
    "        T_val:     An array with one-hot encoded class labels for validation observations, \n",
    "                   shape m times k.\n",
    "        l2:        The regularization strength (\\lambda hyper-paramater).\n",
    "        lr:        Learning rate.\n",
    "        steps:     Number of gradient descent steps to perform.\n",
    "        log_every: Number of steps between progress logs.\n",
    "    \n",
    "    Returns:\n",
    "        An (d+1) times k NumPy array with fitted parameters.\n",
    "    '''\n",
    "    n = X.shape[0]\n",
    "    W = np.copy(W0)\n",
    "    \n",
    "    for step in range(steps):\n",
    "        # Assuming that current model parameters are in `W`, calculate the value of\n",
    "        # the regularized cost function and store it in `cost_val` variable.\n",
    "        \n",
    "        #raise Exception('Complete implementation of gd_fit_reg funcion')\n",
    "        Z = X @ W\n",
    "        S = softmax(Z)\n",
    "        cost_val = xentropy(S, T)\n",
    "        \n",
    "        # Next, calculate the gradient of the regularized cost function w.r.t the\n",
    "        # parameters in `W`. Use this gradient matrix to update `W` (according to\n",
    "        # the gradient descent update rule).\n",
    "        \n",
    "        #raise Exception('Complete implementation of gd_fit_reg funcion')\n",
    "        \n",
    "        grad_val = grad_xentropy(X, S, T)\n",
    "        W = W - lr * grad_val - l2 * W\n",
    "        \n",
    "        P_train = classify(W, X)\n",
    "        train_acc = calc_acc(P_train, T)\n",
    "        \n",
    "        P_val = classify(W, X_val)\n",
    "        val_acc = calc_acc(P_val, T_val)\n",
    "        \n",
    "        if step == 0 or (step + 1) % log_every == 0:\n",
    "            print_log(step+1, cost_val, train_acc, val_acc)\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit regularized multinomial logistic regression model to the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_reg = gd_fit_reg(W0,\n",
    "                   mnist_train_images, mnist_train_labels,\n",
    "                   mnist_val_images, mnist_val_labels,\n",
    "                   l2=0.005, lr=3.0,\n",
    "                   steps=200, log_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_reg = gd_fit_reg(W_reg,\n",
    "                   mnist_train_images, mnist_train_labels,\n",
    "                   mnist_val_images, mnist_val_labels,\n",
    "                   l2=0.005, lr=0.3,\n",
    "                   steps=300, log_every=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we plot the parameters of the regularized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 2))\n",
    "draw_params(plt.gca(), W_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Random.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
